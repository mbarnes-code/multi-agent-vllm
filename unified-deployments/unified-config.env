# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Unified DGX Spark Multi-Agent VLLM Configuration
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Single configuration file for complete DGX Spark deployment including:
# - Kubernetes cluster setup
# - VLLM model serving
# - Multi-agent chatbot stack
# - Multi-modal inference capabilities
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Network Configuration (DGX Spark Hardware)                             │
# └─────────────────────────────────────────────────────────────────────────┘

# Control-plane / API interface reachable from your LAN
CONTROL_PLANE_API_IP=192.168.86.50
CONTROL_PLANE_API_CIDR=192.168.86.50/24
CONTROL_PLANE_INTERFACE=enp65s0
CONTROL_PLANE_CONNECTION="LAN Uplink"

# Optional high-speed (200G) InfiniBand fabric on private subnet for pod traffic
# Leave FABRIC_* unset if you only use the LAN interface
FABRIC_CTRL_IP=10.10.10.1
FABRIC_CTRL_CIDR=10.10.10.1/30
FABRIC_CTRL_INTERFACE=enP7s7
FABRIC_CTRL_CONNECTION="Wired connection 3"

# Worker node configuration
WORKER_NODE_NAME=spark-ba63
WORKER_NODE_IP=10.10.10.2
WORKER_NODE_CIDR=10.10.10.2/30
WORKER_NODE_NETWORK=10.10.10.0/30
WORKER_NODE_INTERFACE=enp1s0f0np0
WORKER_NODE_SSH_TARGET=192.168.86.39
WORKER_NODE_SSH_USER="${SUDO_USER:-$USER}"
WORKER_NODE_SSH_PORT=22

# Worker node InfiniBand IPs for VLLM NCCL communication
WORKER_IPS="10.10.10.2"
WORKER_USER="${WORKER_USER:-$(whoami)}"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Kubernetes Cluster Settings                                            │
# └─────────────────────────────────────────────────────────────────────────┘

# Enable components
ENABLE_K8S_DASHBOARD=1
ENABLE_LONGHORN=1
ENABLE_WORKER_JOIN=1

# Service monitoring
SERVICE_STATUS_NAMESPACES="default kubernetes-dashboard longhorn-system vllm-system agents-system"

# GPU settings
GPU_STATUS_MAX_RETRIES=5
GPU_STATUS_RETRY_DELAY=6

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ VLLM Model Serving Configuration                                       │
# └─────────────────────────────────────────────────────────────────────────┘

# Primary model for multi-agent orchestration
MODEL="openai/gpt-oss-120b"

# Secondary models for specialized agents
SECONDARY_MODELS="meta-llama/Llama-3.1-8B-Instruct,microsoft/Phi-4,openai/gpt-oss-20b"

# VLLM deployment settings
TENSOR_PARALLEL=2
GPU_MEMORY_UTIL=0.90
MAX_MODEL_LEN=8192
VLLM_PORT=8000
VLLM_REPLICAS=1

# Ray distributed serving
RAY_DASHBOARD_PORT=8265
RAY_PORT=6380
RAY_VERSION="2.52.1"

# Container settings
VLLM_IMAGE="nvcr.io/nvidia/vllm:25.11-py3"
SHM_SIZE="16g"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Multi-Agent Chatbot Configuration                                      │
# └─────────────────────────────────────────────────────────────────────────┘

# Agent backend settings
AGENTS_NAMESPACE="agents-system"
AGENT_BACKEND_PORT=8000
AGENT_FRONTEND_PORT=3000

# Database configuration
POSTGRES_DB=chatbot
POSTGRES_USER=chatbot_user
POSTGRES_PASSWORD=chatbot_password
POSTGRES_PORT=5432

# Vector database (Milvus)
MILVUS_PORT=19530
ETCD_PORT=2379
MINIO_PORT=9000

# Agent models mapping
SUPERVISOR_MODEL="openai/gpt-oss-120b"
RAG_AGENT_MODEL="openai/gpt-oss-20b"
CODE_AGENT_MODEL="meta-llama/Llama-3.1-8B-Instruct"
IMAGE_AGENT_MODEL="microsoft/Phi-4"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Multi-Modal Inference Configuration                                    │
# └─────────────────────────────────────────────────────────────────────────┘

# Image generation models
ENABLE_COMFYUI=1
ENABLE_FLUX_MODEL=1
ENABLE_SDXL_MODEL=1

# ComfyUI settings
COMFYUI_PORT=8188
COMFYUI_NAMESPACE="multimodal-system"

# TensorRT optimization
ENABLE_TENSORRT_OPTIMIZATION=1
TENSORRT_PRECISION="fp16"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Storage and Caching Configuration                                      │
# └─────────────────────────────────────────────────────────────────────────┘

# Shared storage paths (should be consistent across both DGX Sparks)
HF_CACHE="/raid/hf-cache"
MODEL_CACHE="/raid/model-cache"
AGENT_DATA="/raid/agent-data"
MULTIMODAL_CACHE="/raid/multimodal-cache"

# Persistent volumes
PVC_STORAGE_CLASS="longhorn"
HF_CACHE_SIZE="500Gi"
MODEL_CACHE_SIZE="1Ti"
AGENT_DATA_SIZE="100Gi"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Authentication and Security                                            │
# └─────────────────────────────────────────────────────────────────────────┘

# HuggingFace token for gated models (Llama, Gemma, etc.)
HF_TOKEN="${HF_TOKEN:-}"

# Minio credentials
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Advanced VLLM Options                                                  │
# └─────────────────────────────────────────────────────────────────────────┘

# Expert parallelism for MoE models (auto-detected for known MoE models)
ENABLE_EXPERT_PARALLEL=true

# Memory and performance settings
SWAP_SPACE=16
TRUST_REMOTE_CODE=false
LOAD_FORMAT="safetensors"

# NCCL/InfiniBand settings (auto-detected from ibdev2netdev)
NCCL_DEBUG="WARN"
# Uncomment to override auto-detection:
# NCCL_IB_DISABLE=0
# NCCL_IB_HCA=mlx5_0,mlx5_1
# NCCL_SOCKET_IFNAME=enp1s0f1np1
# NCCL_NET_GDR_LEVEL=5

# Additional VLLM arguments
EXTRA_ARGS=""

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Monitoring and Observability                                           │
# └─────────────────────────────────────────────────────────────────────────┘

# Enable monitoring stack
ENABLE_PROMETHEUS=1
ENABLE_GRAFANA=1
ENABLE_JAEGER=0

# Monitoring ports
PROMETHEUS_PORT=9090
GRAFANA_PORT=3001
JAEGER_PORT=16686

# Log levels
LOG_LEVEL="INFO"
VLLM_LOG_LEVEL="INFO"
AGENT_LOG_LEVEL="INFO"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Development and Testing                                                │
# └─────────────────────────────────────────────────────────────────────────┘

# Deployment mode (development, staging, production)
DEPLOYMENT_MODE="production"

# Resource limits for development
DEV_CPU_LIMIT="2"
DEV_MEMORY_LIMIT="8Gi"
DEV_GPU_LIMIT="1"

# Production resource requests
PROD_CPU_REQUEST="4"
PROD_MEMORY_REQUEST="16Gi"
PROD_GPU_REQUEST="1"

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ Feature Flags                                                          │
# └─────────────────────────────────────────────────────────────────────────┘

# Enable/disable major components
ENABLE_VLLM=1
ENABLE_MULTI_AGENT=1
ENABLE_MULTIMODAL=1
ENABLE_RAG_SYSTEM=1
ENABLE_CODE_GENERATION=1
ENABLE_IMAGE_UNDERSTANDING=1

# Experimental features
ENABLE_DISTRIBUTED_AGENTS=0
ENABLE_AGENT_MESH=0
ENABLE_CROSS_MODAL_SEARCH=0