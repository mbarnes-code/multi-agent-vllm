# SPDX-FileCopyrightText: Copyright (c) 2025-2026, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# path-check-skip-file

general:
  telemetry:
    logging:
      console:
        _type: console
        level: info
    # Phoenix tracing requires: uv pip install "nvidia-nat[phoenix]" arize-phoenix
    tracing:
      phoenix:
        _type: phoenix
        endpoint: http://localhost:6006/v1/traces
        project: nat_autogen_demo

llms:
  nim_llm:
    _type: nim
    model_name: meta/llama-3.3-70b-instruct
    api_key: ${NVIDIA_API_KEY}
    base_url: https://integrate.api.nvidia.com/v1
    temperature: 0.0
    max_tokens: 1024

  # Evaluator LLM (used for evaluation metrics)
  evaluator_llm:
    _type: nim
    model_name: meta/llama-3.3-70b-instruct
    api_key: ${NVIDIA_API_KEY}
    base_url: https://integrate.api.nvidia.com/v1
    temperature: 0.0
    max_tokens: 2048

function_groups:
  mcp_functions:
    _type: mcp_client
    server:
      transport: streamable-http
      url: "http://localhost:9901/mcp"
    include:
      - current_datetime

functions:
  weather_update_tool:
    _type: nat_autogen_demo/weather_update_autogen
    description: "Get the current weather for a specified city"

workflow:
  _type: autogen_team
  llm_name: nim_llm
  description: "To get the current weather and time in a specific city"
  tool_names: [weather_update_tool, mcp_functions__current_datetime]
  query_processing_agent_name: WeatherAndTimeAgent
  query_processing_agent_instructions: |
    You are an agent that provides the current weather and time information.
    You MUST use your available tools to get accurate information - do NOT make up or guess any data.
    
    REQUIRED WORKFLOW when asked about weather AND time:
    1. FIRST call weather_update_tool with the city name
    2. THEN call mcp_functions__current_datetime with any string (e.g., "now") to get the current time
    3. ONLY after calling BOTH tools, say 'DONE'
    
    CRITICAL: You must call BOTH tools before finishing. Do NOT say 'DONE' until you have results from BOTH tools.
    
    If asked about only weather: call weather_update_tool, then say 'DONE'.
    If asked about only time: call mcp_functions__current_datetime, then say 'DONE'.
    If asked about anything else, respond with 'I can only provide weather and time information.'
  final_response_agent_name: FinalResponseAgent
  final_response_agent_instructions: |
    You are the final response agent.
    Your role is to provide a concise and clear answer based on the information provided by other agents.
    Once you are done, reply with the final answer and then say 'APPROVE'.

eval:
  general:
    output:
      dir: ./.tmp/nat/examples/frameworks/nat_autogen_demo/eval/
      cleanup: true
    dataset:
      _type: json
      file_path: examples/frameworks/nat_autogen_demo/data/eval_dataset.json
    profiler:
      token_uniqueness_forecast: true
      workflow_runtime_forecast: true
      compute_llm_metrics: true
      csv_exclude_io_text: true
      prompt_caching_prefixes:
        enable: true
        min_frequency: 0.1
      bottleneck_analysis:
        enable_nested_stack: true
      concurrency_spike_analysis:
        enable: true
        spike_threshold: 5

  evaluators:
    accuracy:
      _type: ragas
      metric: AnswerAccuracy
      llm_name: evaluator_llm
    groundedness:
      _type: ragas
      metric: ResponseGroundedness
      llm_name: evaluator_llm
    trajectory_accuracy:
      _type: trajectory
      llm_name: evaluator_llm
