{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0a43de-41ab-422a-ba7b-89a644b656a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Getting started with MAKER\n",
    "#\n",
    "# This notebook illustrates the core components of MAKER on\n",
    "# the Towers of Hanoi domain illustrated in the paper:\n",
    "# Solving a Million-step LLM Task with Zero Errors (arxiv.org/abs/2511.09030).\n",
    "#\n",
    "# Practical experiments for solving the full 20 disk (1M+ step) task\n",
    "# require some method of parallelization not included here,\n",
    "# e.g., via asynchronous or batch APIs.\n",
    "#\n",
    "# We hope this example serves as a starting point for experimenting with\n",
    "# different aspects of the method, and applying to new domains.\n",
    "#\n",
    "# Enjoy!\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c64c1b-577a-4e3e-a681-1160df8b1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from prompts import create_prompts\n",
    "from parsers import parse_move_state_flag as parse_move_state\n",
    "from toh_simulator import TowerOfHanoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a80e62-07ed-4b5d-aa70-e19b4fba0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up method to call API\n",
    "\n",
    "client = OpenAI() # Assumes OPENAI_KEY is set as environment variable\n",
    "\n",
    "def call_llm(model, system_prompt, user_prompt, max_tokens=750, temperature=0.1):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64830d20-f2f6-44d0-8dda-aef7925d7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State: [[4, 3, 2, 1], [], []]\n"
     ]
    }
   ],
   "source": [
    "# Set up task with some even number of disks.\n",
    "n_disks = 4\n",
    "state = str([[i+1 for i in range(n_disks)][::-1], [], []])\n",
    "print(\"Initial State:\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf7ed0f-a1ba-4fa2-8f17-9a2149a04ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for MAKER\n",
    "model = 'gpt-4.1-mini'\n",
    "temperature = 0.1\n",
    "max_tokens = 750\n",
    "n_steps = 2**n_disks - 1\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71ea94a-0e30-4f0c-a5f2-c2e938c7fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms from Figure 2 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2a921b-e4d1-4ce1-bedd-a0d01347f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vote(x, \n",
    "             model, \n",
    "             max_tokens=750, \n",
    "             temperature=0.1, \n",
    "             max_tries=10):\n",
    "\n",
    "    for i in range(max_tries): # max_tries can be useful for debugging\n",
    "        prev_move, state = x\n",
    "        system_prompt, user_prompt = create_prompts(prev_move, state)\n",
    "        response = call_llm(model, system_prompt, user_prompt, max_tokens, temperature)\n",
    "        try:\n",
    "            move, state = parse_move_state(response, n_disks)\n",
    "            return move, state\n",
    "        except ValueError:\n",
    "            print(f'Response {i} flagged')\n",
    "\n",
    "    raise ValueError(f'No valid response in {max_tries} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41750717-0e18-4716-9f0d-2d6b686b999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_voting(x, \n",
    "              model, \n",
    "              k, \n",
    "              max_tokens=750, \n",
    "              temperature=0.1,\n",
    "              max_tries=10):\n",
    "    \n",
    "    vote_counts = {}\n",
    "    for i in range(max_tries): # max_tries can be useful for debugging\n",
    "        print(\"Vote\", i)\n",
    "        \n",
    "        # Get new vote\n",
    "        y = get_vote(x, model, max_tokens, temperature, max_tries)\n",
    "        if y not in vote_counts:\n",
    "            vote_counts[y] = 1\n",
    "        else:\n",
    "            vote_counts[y] += 1\n",
    "\n",
    "        print(vote_counts)\n",
    "\n",
    "        # Check decision condition\n",
    "        if len(vote_counts) == 1:\n",
    "            if vote_counts[y] == k:\n",
    "                return y\n",
    "        else:\n",
    "            alt_max = max([vote_counts[z] for z in vote_counts if z != y])\n",
    "            if vote_counts[y] >= alt_max + k:\n",
    "                return y\n",
    "\n",
    "    raise ValueError(f'No decision reached in {max_tries} votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdb7ee4-ca53-4117-8cc1-6e900e577e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(initial_state, \n",
    "                      model, \n",
    "                      k, \n",
    "                      n_steps, \n",
    "                      max_tokens=750, \n",
    "                      temperature=0.1, \n",
    "                      max_tries=10):\n",
    "    actions = []\n",
    "    state = initial_state[:]\n",
    "    action = None\n",
    "    for i in range(n_steps):\n",
    "        print(f\"Step {i} of {n_steps}\")\n",
    "        x = (action, state)\n",
    "        action, state = do_voting(x, model, k, max_tokens, temperature, max_tries)\n",
    "        actions.append(action)\n",
    "        print()\n",
    "    print(\"Done.\")\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233dd4c2-f67f-49ec-8ce3-5dfbd58af003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 of 15\n",
      "Vote 0\n",
      "{((1, 0, 1), ((4, 3, 2), (1,), ())): 1}\n",
      "Vote 1\n",
      "{((1, 0, 1), ((4, 3, 2), (1,), ())): 2}\n",
      "\n",
      "Step 1 of 15\n",
      "Vote 0\n",
      "{((2, 0, 2), ((4, 3), (1,), (2,))): 1}\n",
      "Vote 1\n",
      "{((2, 0, 2), ((4, 3), (1,), (2,))): 2}\n",
      "\n",
      "Step 2 of 15\n",
      "Vote 0\n",
      "Response 0 flagged\n",
      "{((1, 1, 2), ((4, 3), (), (2, 1))): 1}\n",
      "Vote 1\n",
      "Response 0 flagged\n",
      "{((1, 1, 2), ((4, 3), (), (2, 1))): 2}\n",
      "\n",
      "Step 3 of 15\n",
      "Vote 0\n",
      "{((3, 0, 1), ((4,), (3,), (2, 1))): 1}\n",
      "Vote 1\n",
      "{((3, 0, 1), ((4,), (3,), (2, 1))): 2}\n",
      "\n",
      "Step 4 of 15\n",
      "Vote 0\n",
      "Response 0 flagged\n",
      "Response 1 flagged\n",
      "Response 2 flagged\n",
      "{((1, 2, 0), ((4, 1), (3,), (2,))): 1}\n",
      "Vote 1\n",
      "Response 0 flagged\n",
      "Response 1 flagged\n",
      "{((1, 2, 0), ((4, 1), (3,), (2,))): 2}\n",
      "\n",
      "Step 5 of 15\n",
      "Vote 0\n",
      "{((2, 2, 1), ((4, 1), (3, 2), ())): 1}\n",
      "Vote 1\n",
      "{((2, 2, 1), ((4, 1), (3, 2), ())): 2}\n",
      "\n",
      "Step 6 of 15\n",
      "Vote 0\n",
      "{((1, 0, 1), ((4,), (3, 2, 1), ())): 1}\n",
      "Vote 1\n",
      "{((1, 0, 1), ((4,), (3, 2, 1), ())): 2}\n",
      "\n",
      "Step 7 of 15\n",
      "Vote 0\n",
      "{((4, 0, 2), ((), (3, 2, 1), (4,))): 1}\n",
      "Vote 1\n",
      "{((4, 0, 2), ((), (3, 2, 1), (4,))): 2}\n",
      "\n",
      "Step 8 of 15\n",
      "Vote 0\n",
      "{((1, 1, 2), ((), (3, 2), (4, 1))): 1}\n",
      "Vote 1\n",
      "{((1, 1, 2), ((), (3, 2), (4, 1))): 2}\n",
      "\n",
      "Step 9 of 15\n",
      "Vote 0\n",
      "{((2, 1, 0), ((2,), (3,), (4, 1))): 1}\n",
      "Vote 1\n",
      "{((2, 1, 0), ((2,), (3,), (4, 1))): 2}\n",
      "\n",
      "Step 10 of 15\n",
      "Vote 0\n",
      "{((1, 2, 0), ((2, 1), (3,), (4,))): 1}\n",
      "Vote 1\n",
      "Response 0 flagged\n",
      "Response 1 flagged\n",
      "Response 2 flagged\n",
      "Response 3 flagged\n",
      "Response 4 flagged\n",
      "{((1, 2, 0), ((2, 1), (3,), (4,))): 2}\n",
      "\n",
      "Step 11 of 15\n",
      "Vote 0\n",
      "{((3, 1, 2), ((2, 1), (), (4, 3))): 1}\n",
      "Vote 1\n",
      "{((3, 1, 2), ((2, 1), (), (4, 3))): 2}\n",
      "\n",
      "Step 12 of 15\n",
      "Vote 0\n",
      "{((1, 0, 1), ((2,), (1,), (4, 3))): 1}\n",
      "Vote 1\n",
      "{((1, 0, 1), ((2,), (1,), (4, 3))): 2}\n",
      "\n",
      "Step 13 of 15\n",
      "Vote 0\n",
      "{((2, 0, 2), ((), (1,), (4, 3, 2))): 1}\n",
      "Vote 1\n",
      "{((2, 0, 2), ((), (1,), (4, 3, 2))): 2}\n",
      "\n",
      "Step 14 of 15\n",
      "Vote 0\n",
      "{((1, 1, 2), ((), (), (4, 3, 2, 1))): 1}\n",
      "Vote 1\n",
      "{((1, 1, 2), ((), (), (4, 3, 2, 1))): 2}\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "actions = generate_solution(state, model, k, n_steps, max_tokens, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66a644b-239f-424f-aad6-41fcf3102c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State: {'0': [4, 3, 2, 1], '1': [], '2': []}\n",
      "Action: (1, 0, 1)\n",
      "State: {'0': [4, 3, 2], '1': [1], '2': []}\n",
      "Action: (2, 0, 2)\n",
      "State: {'0': [4, 3], '1': [1], '2': [2]}\n",
      "Action: (1, 1, 2)\n",
      "State: {'0': [4, 3], '1': [], '2': [2, 1]}\n",
      "Action: (3, 0, 1)\n",
      "State: {'0': [4], '1': [3], '2': [2, 1]}\n",
      "Action: (1, 2, 0)\n",
      "State: {'0': [4, 1], '1': [3], '2': [2]}\n",
      "Action: (2, 2, 1)\n",
      "State: {'0': [4, 1], '1': [3, 2], '2': []}\n",
      "Action: (1, 0, 1)\n",
      "State: {'0': [4], '1': [3, 2, 1], '2': []}\n",
      "Action: (4, 0, 2)\n",
      "State: {'0': [], '1': [3, 2, 1], '2': [4]}\n",
      "Action: (1, 1, 2)\n",
      "State: {'0': [], '1': [3, 2], '2': [4, 1]}\n",
      "Action: (2, 1, 0)\n",
      "State: {'0': [2], '1': [3], '2': [4, 1]}\n",
      "Action: (1, 2, 0)\n",
      "State: {'0': [2, 1], '1': [3], '2': [4]}\n",
      "Action: (3, 1, 2)\n",
      "State: {'0': [2, 1], '1': [], '2': [4, 3]}\n",
      "Action: (1, 0, 1)\n",
      "State: {'0': [2], '1': [1], '2': [4, 3]}\n",
      "Action: (2, 0, 2)\n",
      "State: {'0': [], '1': [1], '2': [4, 3, 2]}\n",
      "Action: (1, 1, 2)\n",
      "State: {'0': [], '1': [], '2': [4, 3, 2, 1]}\n",
      "SOLVED!\n"
     ]
    }
   ],
   "source": [
    "# Test solution\n",
    "toh = TowerOfHanoi(n_disks)\n",
    "print(\"Initial State:\", toh.get_state())\n",
    "for action in actions:\n",
    "    \n",
    "    sim_state, move_valid, done, sim_message = toh.act(action)\n",
    "\n",
    "    print(\"Action:\", action)\n",
    "    print(\"State:\", sim_state)\n",
    "    \n",
    "    if not move_valid:\n",
    "        print(\"INVALID MOVE!\")\n",
    "        break\n",
    "        \n",
    "    if toh.is_solved():\n",
    "        print(\"SOLVED!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396531d-7675-4112-86d7-df1b3a22891c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
